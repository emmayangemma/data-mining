# -*- coding: utf-8 -*-
"""
Created on Thu May  2 13:15:57 2019

@author: Emma
"""

import numpy as np
import pandas as pd
from datetime import datetime
import matplotlib.pyplot as plt
import json


# choose ten companies with relative complete data.
# 7181       274
# 1066       275
# 06516F     275
# 4707       276
# 06516G     276
# 9873       276
# 3662WC     277
# 06515B     278
# 3662       279
# 06516J     280

# Read the data as dataframe
df = pd.read_csv("C:\Users\Emma\stock_df.csv")

#choosing the stock 7181
df1 = df[df['stockCode']=='7181']
df1['stockDate2'] = df1['stockDate']+' '+df1['stockTime']
df1.stockDate2 = pd.to_datetime(df1.stockDate2)
df1.stockDate = pd.to_datetime(df1.stockDate)
df1 = df1[['stockCode','stockName','stockDate','stockDate2','Open','High','Low','Last','Chg %']]
df1.head(5)



time series gragh of 7181

%matplotlib inline
%pylab inline
pylab.rcParams['figure.figsize'] = (15, 9) 
# df1['Last'].plot(grid=True)
name = df1['stockName'].values[0]
plt.plot('stockDate2', 'Last', data=df1)
plt.title(f'{name}')
plt.xlabel('Date')
plt.ylabel('Price')
plt.grid(True)


# News data will be used here to see if it has any affection on stock price.


import json
import pandas as pd


# Load the json file
with open('E:/Google Drive/Data Science/7005 Data Mining/Milestone 3/news.json') as json_file:
    data = json.loads(json_file.read())

# fromating the news into csv file which is easily used and processed
header_list = ['name', 'code', 'date', 'time', 'content']
news_df = pd.DataFrame(columns=header_list)
news_cnt = []

for i in data:
    name = i['stock_name']
    code = i['stock_code']
    date = i['publish_date']
    time = i['publish_time']
    content = i['Content']
    news_cnt.append([name, code, date, time, content])
#     if code =='7181':
#         print([name, code, date, time, content])

news_df_part = pd.DataFrame(news_cnt, columns=header_list)
news_df = news_df.append(news_df_part)

news_df.to_csv('C:\Users\Emma\news.csv', encoding='utf-8')



import pandas as pd
import nltk
nltk.download('punkt')
nltk.download('stopwords')
from nltk.corpus import stopwords


#Extract the text from content and do analysis
news_csv = pd.read_csv("C:\Users\Emma\news.csv", index_col=0)
news1 = news_csv[news_csv['code']=='7181']

news1['stockdate'] = pd.to_datetime(news1.date)

#remove all the unnecessary symbols
news1['content'] = news1.content.str.replace("[^\w\s]"," ").str.lower().str.rstrip("\n\r")

#Tokenization
news1['content'] = news1.apply(lambda row: nltk.word_tokenize(row['content']), axis=1)

#Remove stop words
stop = stopwords.words('english')
news1['content'] = news1['content'].apply(lambda x: [item for item in x if item not in stop])

news1 = news1[['name','code','stockdate','content']]
print(news1)


#using SentimentIntensityAnalyzer to analyze the news
nltk.download('vader_lexicon')
from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA

sia = SIA()
results = []

#Convert list to strings and apply polarity scores to know if the news is good or bad
news1['content2'] = news1['content'].str.join(" ")
news1['Negative'] = news1['content2'].apply(lambda x: sia.polarity_scores(x)['neg'])
news1['Neutral'] = news1['content2'].apply(lambda x: sia.polarity_scores(x)['neu'])
news1['Positive'] = news1['content2'].apply(lambda x: sia.polarity_scores(x)['pos'])
news1['Compound'] = news1['content2'].apply(lambda x: sia.polarity_scores(x)['compound'])

news1.head()
